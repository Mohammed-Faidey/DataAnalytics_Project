{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        \n        #print(os.path.join(dirname, filename))\n        pass\n    \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-24T02:25:59.479629Z","iopub.execute_input":"2022-06-24T02:25:59.480461Z","iopub.status.idle":"2022-06-24T02:26:00.623313Z","shell.execute_reply.started":"2022-06-24T02:25:59.480347Z","shell.execute_reply":"2022-06-24T02:26:00.622222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to prevent cleanup message from tensorflow as there are alot of them appear\nimport tensorflow as tf\n\ntf.get_logger().setLevel('INFO')","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:00.627399Z","iopub.execute_input":"2022-06-24T02:26:00.628311Z","iopub.status.idle":"2022-06-24T02:26:06.977374Z","shell.execute_reply.started":"2022-06-24T02:26:00.628275Z","shell.execute_reply":"2022-06-24T02:26:06.976115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DATA_PATH = \"/kaggle/input/nft-art-dataset/\"","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:06.980046Z","iopub.execute_input":"2022-06-24T02:26:06.981532Z","iopub.status.idle":"2022-06-24T02:26:06.992455Z","shell.execute_reply.started":"2022-06-24T02:26:06.981478Z","shell.execute_reply":"2022-06-24T02:26:06.989333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading The DataSet","metadata":{}},{"cell_type":"code","source":"data  = pd.read_csv(INPUT_DATA_PATH + \"dataset/dataset.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:06.996232Z","iopub.execute_input":"2022-06-24T02:26:06.99699Z","iopub.status.idle":"2022-06-24T02:26:07.059042Z","shell.execute_reply.started":"2022-06-24T02:26:06.996946Z","shell.execute_reply":"2022-06-24T02:26:07.057635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.062062Z","iopub.execute_input":"2022-06-24T02:26:07.06251Z","iopub.status.idle":"2022-06-24T02:26:07.10325Z","shell.execute_reply.started":"2022-06-24T02:26:07.062468Z","shell.execute_reply":"2022-06-24T02:26:07.101941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['creator'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.108794Z","iopub.execute_input":"2022-06-24T02:26:07.109507Z","iopub.status.idle":"2022-06-24T02:26:07.136109Z","shell.execute_reply.started":"2022-06-24T02:26:07.109447Z","shell.execute_reply":"2022-06-24T02:26:07.134742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Show the top 5 creators","metadata":{}},{"cell_type":"code","source":"top_creators = data['creator'].value_counts().head(5)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.140025Z","iopub.execute_input":"2022-06-24T02:26:07.140569Z","iopub.status.idle":"2022-06-24T02:26:07.150516Z","shell.execute_reply.started":"2022-06-24T02:26:07.140519Z","shell.execute_reply":"2022-06-24T02:26:07.149098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### make a dictionary of top5 creators ","metadata":{}},{"cell_type":"code","source":"top_creators_stats = dict()\nfor i in range(len(top_creators)):\n    top_creators_stats[top_creators.index[i]] = top_creators.values[i]\ntop_creators_stats","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.155266Z","iopub.execute_input":"2022-06-24T02:26:07.15622Z","iopub.status.idle":"2022-06-24T02:26:07.16759Z","shell.execute_reply.started":"2022-06-24T02:26:07.156169Z","shell.execute_reply":"2022-06-24T02:26:07.166023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### make a list of top file creators","metadata":{}},{"cell_type":"code","source":"top_creators_list = []\nfor a, b in enumerate(top_creators_stats.keys()):\n    top_creators_list.append(b)\n    \nprint(top_creators_list)\nprint(len(top_creators_list))","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.17075Z","iopub.execute_input":"2022-06-24T02:26:07.171579Z","iopub.status.idle":"2022-06-24T02:26:07.187174Z","shell.execute_reply.started":"2022-06-24T02:26:07.171527Z","shell.execute_reply":"2022-06-24T02:26:07.185679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data2= data.copy()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.194414Z","iopub.execute_input":"2022-06-24T02:26:07.194836Z","iopub.status.idle":"2022-06-24T02:26:07.205019Z","shell.execute_reply.started":"2022-06-24T02:26:07.1948Z","shell.execute_reply":"2022-06-24T02:26:07.202673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# select top 5 creators and make a copied dataframe for them\n","metadata":{}},{"cell_type":"code","source":"data2 = data2[data2['creator'].apply(lambda x : x in top_creators_list)]\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.207824Z","iopub.execute_input":"2022-06-24T02:26:07.215234Z","iopub.status.idle":"2022-06-24T02:26:07.233135Z","shell.execute_reply.started":"2022-06-24T02:26:07.215178Z","shell.execute_reply":"2022-06-24T02:26:07.231904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data2['creator'].unique())\nprint(len(data2['creator'].unique()))","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.238698Z","iopub.execute_input":"2022-06-24T02:26:07.240176Z","iopub.status.idle":"2022-06-24T02:26:07.258557Z","shell.execute_reply.started":"2022-06-24T02:26:07.240116Z","shell.execute_reply":"2022-06-24T02:26:07.257268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### so this is info of top artists","metadata":{}},{"cell_type":"code","source":"data2","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.26175Z","iopub.execute_input":"2022-06-24T02:26:07.266212Z","iopub.status.idle":"2022-06-24T02:26:07.308957Z","shell.execute_reply.started":"2022-06-24T02:26:07.266164Z","shell.execute_reply":"2022-06-24T02:26:07.306998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Working on photo data not videos or gifs","metadata":{}},{"cell_type":"code","source":"PHOTO_DATA = data2[data2['type' ]== 'PHOTO']","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.311225Z","iopub.execute_input":"2022-06-24T02:26:07.312804Z","iopub.status.idle":"2022-06-24T02:26:07.324035Z","shell.execute_reply.started":"2022-06-24T02:26:07.312749Z","shell.execute_reply":"2022-06-24T02:26:07.322667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PHOTO_DATA['type'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.327302Z","iopub.execute_input":"2022-06-24T02:26:07.33048Z","iopub.status.idle":"2022-06-24T02:26:07.340299Z","shell.execute_reply.started":"2022-06-24T02:26:07.330423Z","shell.execute_reply":"2022-06-24T02:26:07.338771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PHOTO_DATA","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.343803Z","iopub.execute_input":"2022-06-24T02:26:07.348947Z","iopub.status.idle":"2022-06-24T02:26:07.393174Z","shell.execute_reply.started":"2022-06-24T02:26:07.348846Z","shell.execute_reply":"2022-06-24T02:26:07.391897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## clean the path feature by removing the first two chars -> ./ \n## as we will use the path laterly without the need for to chars -> ./\n","metadata":{}},{"cell_type":"code","source":"PHOTO_DATA['path'] = PHOTO_DATA['path'].apply(lambda x : x.replace('./', ''))","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.397542Z","iopub.execute_input":"2022-06-24T02:26:07.397932Z","iopub.status.idle":"2022-06-24T02:26:07.407017Z","shell.execute_reply.started":"2022-06-24T02:26:07.397869Z","shell.execute_reply":"2022-06-24T02:26:07.405636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PHOTO_DATA\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.409413Z","iopub.execute_input":"2022-06-24T02:26:07.410411Z","iopub.status.idle":"2022-06-24T02:26:07.448133Z","shell.execute_reply.started":"2022-06-24T02:26:07.410322Z","shell.execute_reply":"2022-06-24T02:26:07.446798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%cd /kaggle/working \n#%mkdir dataset\n#%mkdir top5creator_images","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.450503Z","iopub.execute_input":"2022-06-24T02:26:07.451477Z","iopub.status.idle":"2022-06-24T02:26:07.45666Z","shell.execute_reply.started":"2022-06-24T02:26:07.45141Z","shell.execute_reply":"2022-06-24T02:26:07.455115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%pwd","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.458759Z","iopub.execute_input":"2022-06-24T02:26:07.459741Z","iopub.status.idle":"2022-06-24T02:26:07.472419Z","shell.execute_reply.started":"2022-06-24T02:26:07.459696Z","shell.execute_reply":"2022-06-24T02:26:07.470333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DDPATH = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.475064Z","iopub.execute_input":"2022-06-24T02:26:07.475843Z","iopub.status.idle":"2022-06-24T02:26:07.486Z","shell.execute_reply.started":"2022-06-24T02:26:07.475797Z","shell.execute_reply":"2022-06-24T02:26:07.483504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir(INPUT_DATA_PATH + 'dataset/image'))","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.489846Z","iopub.execute_input":"2022-06-24T02:26:07.491436Z","iopub.status.idle":"2022-06-24T02:26:07.506612Z","shell.execute_reply.started":"2022-06-24T02:26:07.491379Z","shell.execute_reply":"2022-06-24T02:26:07.50549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%rm -r top5creators/","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.508307Z","iopub.execute_input":"2022-06-24T02:26:07.508962Z","iopub.status.idle":"2022-06-24T02:26:07.515533Z","shell.execute_reply.started":"2022-06-24T02:26:07.508922Z","shell.execute_reply":"2022-06-24T02:26:07.513878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create Two Directories \n\n## The First Directory is top5creators\n> in this directory I Will make new SubDirectories based on names of top5 creators\n\n> then i will copy the images of each creator from the dataset/images \n\n> to each creator direactory that these images belong to him\n\n> e.g. \n\n###  top5creators/\n                          \n                1. elenasteem/ \n                2. richardfyates/ \n                3. artxmike/\n                4. doze/\n                5. elgeko/\n\n## The Second Directory is top5creators_images \n\n> In this directory i will make 3 sub directories train , val , test \n\n> In each one of these directories I made a 5 sub directories , mean , a new sub directorey form each creator\n\n> so in the top5creators_images/train we will find there are 5 directories based on the top 5 creators\n\n> e.g.\n\n### 1. top5creators_images/\n    \n          1.1 train/\n          \n                1.1.1 elenasteem/ \n                1.1.2 richardfyates/ \n                1.1.3 artxmike/\n                1.1.4 doze/\n                1.1.5 elgeko/\n      \n          1.2 val/\n          \n                  same in train sub dirs\n                  \n          1.3 test/\n          \n                  same in val sub dirs","metadata":{}},{"cell_type":"code","source":"\nos.makedirs('top5creators')\nos.makedirs(\"top5creators_images\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.51774Z","iopub.execute_input":"2022-06-24T02:26:07.518467Z","iopub.status.idle":"2022-06-24T02:26:07.530608Z","shell.execute_reply.started":"2022-06-24T02:26:07.51838Z","shell.execute_reply":"2022-06-24T02:26:07.527742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%ls","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:07.533774Z","iopub.execute_input":"2022-06-24T02:26:07.534537Z","iopub.status.idle":"2022-06-24T02:26:08.456839Z","shell.execute_reply.started":"2022-06-24T02:26:07.534485Z","shell.execute_reply":"2022-06-24T02:26:08.455368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top5_creators_dir ='top5creators/'","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:08.459429Z","iopub.execute_input":"2022-06-24T02:26:08.460198Z","iopub.status.idle":"2022-06-24T02:26:08.467953Z","shell.execute_reply.started":"2022-06-24T02:26:08.460145Z","shell.execute_reply":"2022-06-24T02:26:08.466733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### create the sub dirs for each creator","metadata":{}},{"cell_type":"code","source":"for creator in top_creators_list:\n    os.makedirs(top5_creators_dir + creator)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:08.469658Z","iopub.execute_input":"2022-06-24T02:26:08.471168Z","iopub.status.idle":"2022-06-24T02:26:08.482038Z","shell.execute_reply.started":"2022-06-24T02:26:08.471116Z","shell.execute_reply":"2022-06-24T02:26:08.480488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%ls top5creators/","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:08.49782Z","iopub.execute_input":"2022-06-24T02:26:08.499137Z","iopub.status.idle":"2022-06-24T02:26:09.346635Z","shell.execute_reply.started":"2022-06-24T02:26:08.499087Z","shell.execute_reply":"2022-06-24T02:26:09.345354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PHOTO_DATA[PHOTO_DATA['creator' ]== top_creators_list[0]]['path']","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:09.348588Z","iopub.execute_input":"2022-06-24T02:26:09.349061Z","iopub.status.idle":"2022-06-24T02:26:09.363621Z","shell.execute_reply.started":"2022-06-24T02:26:09.349013Z","shell.execute_reply":"2022-06-24T02:26:09.362352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DATA_PATH","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:09.365711Z","iopub.execute_input":"2022-06-24T02:26:09.366945Z","iopub.status.idle":"2022-06-24T02:26:09.375256Z","shell.execute_reply.started":"2022-06-24T02:26:09.366875Z","shell.execute_reply":"2022-06-24T02:26:09.373879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%ls","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:09.377567Z","iopub.execute_input":"2022-06-24T02:26:09.3787Z","iopub.status.idle":"2022-06-24T02:26:10.100659Z","shell.execute_reply.started":"2022-06-24T02:26:09.37864Z","shell.execute_reply":"2022-06-24T02:26:10.099315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### copy images form dataset/images of top 5 creators\n### to thier new location in top5creators\n","metadata":{}},{"cell_type":"code","source":"# copy images of these creators to another images folder called top5_images\nfrom tqdm import tqdm\nimport shutil\nimport random\n\ni = 0\nfor creator in top_creators_list:\n    \n    for path in tqdm(PHOTO_DATA[PHOTO_DATA['creator' ]== creator]['path']):\n        i+= 1\n    \n        #print(path)\n\n        shutil.copy(INPUT_DATA_PATH + path , top5_creators_dir + creator ) \n    #print(i)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:10.103222Z","iopub.execute_input":"2022-06-24T02:26:10.103815Z","iopub.status.idle":"2022-06-24T02:26:22.054856Z","shell.execute_reply.started":"2022-06-24T02:26:10.103758Z","shell.execute_reply":"2022-06-24T02:26:22.053637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test if we succuesfully make a folder for top5 creators \n#and copy their images from images in the data set to the new directory for each one of them\n\n%ls top5creators/doze","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:22.056537Z","iopub.execute_input":"2022-06-24T02:26:22.057779Z","iopub.status.idle":"2022-06-24T02:26:22.779302Z","shell.execute_reply.started":"2022-06-24T02:26:22.05773Z","shell.execute_reply":"2022-06-24T02:26:22.77795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### copy images form dataset/images of top 5 creators\n### to thier new location in top5creators_images\n### and split them automatically to train val test split\n### and each directory of train, val, test,\n### has inside subdirs for each creator\n### then the images","metadata":{}},{"cell_type":"code","source":"os.makedirs('top5creators_images/train')\nos.makedirs('top5creators_images/test')\nos.makedirs('top5creators_images/val')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:22.781518Z","iopub.execute_input":"2022-06-24T02:26:22.781972Z","iopub.status.idle":"2022-06-24T02:26:22.7889Z","shell.execute_reply.started":"2022-06-24T02:26:22.781925Z","shell.execute_reply":"2022-06-24T02:26:22.787848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport shutil\nimport random\n\nroot_dir = '/kaggle/working/' # data root path\nclasses_dir = top_creators_list #total labels\n\nval_ratio = 0.15\ntest_ratio = 0.05\n\nfor cls in classes_dir:\n    \n    \n    if not os.path.isdir(root_dir + 'top5creators_images/train/' + cls):\n        os.makedirs(root_dir + 'top5creators_images/train/' + cls)\n        #print(\"root_dir + 'top5creators_images/train/' + cls -> \" ,root_dir + 'top5creators_images/train/' + cls,\"\\n\" )\n        \n    if not os.path.isdir(root_dir + 'top5creators_images/val/' + cls):\n        os.makedirs(root_dir +'top5creators_images/val/' + cls)\n        #print(\"root_dir + 'top5creators_images/val/' + cls -> \" ,root_dir + 'top5creators_images/val/' + cls,\"\\n\" )\n        \n    if not os.path.isdir(root_dir + 'top5creators_images/test/' + cls):\n        os.makedirs(root_dir +'top5creators_images/test/' + cls)\n        #print(\"root_dir + 'top5creators_images/test/' + cls -> \" ,root_dir + 'top5creators_images/test/' + cls ,\"\\n\" )\n\n\n    # Creating partitions of the data after shuffeling\n    src = root_dir + 'top5creators/' + cls # Folder to copy images from\n    #print(\"src -> \" , src, \"\\n\")\n\n    allFileNames = os.listdir(src)\n    #print(\"allFileNames -> \" , allFileNames ,\"\\n\")\n\n    np.random.shuffle(allFileNames)\n\n    train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n                                                              [int(len(allFileNames)* (1 - (val_ratio + test_ratio))), \n                                                               int(len(allFileNames)* (1 - test_ratio))])\n\n    #print(\"train_FileNames -> \" , train_FileNames ,\"\\n\")\n    #print(\"val_FileNames -> \" , val_FileNames ,\"\\n\")\n    #print(\"test_FileNames -> \" , test_FileNames ,\"\\n\")\n    #print(\"==================================== \\n\")\n\n\n    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n    #print(\"train_FileNames -> \" , train_FileNames ,\"\\n\")\n\n    val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n    #print(\"val_FileNames -> \" , val_FileNames ,\"\\n\")\n\n    test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n    #print(\"test_FileNames -> \" , test_FileNames ,\"\\n\")\n\n\n    #print('Total images: ', len(allFileNames))\n    #print('Training: ', len(train_FileNames))\n    #print('Validation: ', len(val_FileNames))\n    #print('Testing: ', len(test_FileNames))\n\n\n    #print(\"*******************************************\")\n    # Copy-pasting images\n    for name in train_FileNames:\n        shutil.copy(name, root_dir + 'top5creators_images/' +'train/' + cls)\n        #print(\"name -> \", name, \"\\n\")\n        #print(\" root_dir + 'top5creators_images/' +'train/' + cls -> \",  root_dir + 'top5creators_images/' +'train/' + cls ,\"\\n\")\n\n    #print(\"-----------------------------------------\")\n    for name in val_FileNames:\n        shutil.copy(name, root_dir+ 'top5creators_images/' +'val/' + cls)\n        #print(\"name -> \", name, \"\\n\")\n        #print(\" root_dir + 'top5creators_images/' +'val/' + cls -> \",  root_dir + 'top5creators_images/' +'val/' + cls ,\"\\n\")\n\n    #print(\"-----------------------------------------\") \n    for name in test_FileNames:\n        shutil.copy(name, root_dir+ 'top5creators_images/' +'test/' + cls)\n        #print(\"name -> \", name, \"\\n\")\n        #print(\" root_dir + 'top5creators_images/' +'test/' + cls -> \",  root_dir + 'top5creators_images/' +'test/' + cls ,\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:22.794201Z","iopub.execute_input":"2022-06-24T02:26:22.794538Z","iopub.status.idle":"2022-06-24T02:26:26.227779Z","shell.execute_reply.started":"2022-06-24T02:26:22.7945Z","shell.execute_reply":"2022-06-24T02:26:26.226439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> make a test to make sure that the copied images is belong to the same creator\n\n> in the dataset.csv and our copy is sucssesfuly\n\n> so just take the cid of the below image with out taking the extintion eg. .png , .jpg or .jpeg \n\n> just the cid","metadata":{}},{"cell_type":"code","source":"PHOTO_DATA[PHOTO_DATA['cid'] == 'QmRr5azUCkfUWb4V1BsbVYmkHtY4TGJYCydiqurPoo1TeN']","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:26.234734Z","iopub.execute_input":"2022-06-24T02:26:26.238179Z","iopub.status.idle":"2022-06-24T02:26:26.303628Z","shell.execute_reply.started":"2022-06-24T02:26:26.238113Z","shell.execute_reply":"2022-06-24T02:26:26.302509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> so after looking to creator name we find our copy is succesfuly done","metadata":{}},{"cell_type":"markdown","source":"# Loading Data","metadata":{}},{"cell_type":"code","source":"# make some configuration for batch_size , image_height, image_width \n# we make a low batch_size to save our memory from crashing\n\nbatch_size = 32\nimg_height = 180\nimg_width = 180","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:26.305442Z","iopub.execute_input":"2022-06-24T02:26:26.305908Z","iopub.status.idle":"2022-06-24T02:26:27.404233Z","shell.execute_reply.started":"2022-06-24T02:26:26.305845Z","shell.execute_reply":"2022-06-24T02:26:27.396124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading train images ","metadata":{}},{"cell_type":"code","source":"train_ds = tf.keras.utils.image_dataset_from_directory(\n  '/kaggle/working/top5creators_images/train',\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:27.411497Z","iopub.execute_input":"2022-06-24T02:26:27.412458Z","iopub.status.idle":"2022-06-24T02:26:33.160309Z","shell.execute_reply.started":"2022-06-24T02:26:27.412406Z","shell.execute_reply":"2022-06-24T02:26:33.157951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> as we can see we succsfuly loading 310 images from the trian directory \n\n> that they belong to the top 5 creators , we treat them as classes for our images dataset","metadata":{}},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:33.161903Z","iopub.execute_input":"2022-06-24T02:26:33.162239Z","iopub.status.idle":"2022-06-24T02:26:33.176153Z","shell.execute_reply.started":"2022-06-24T02:26:33.16221Z","shell.execute_reply":"2022-06-24T02:26:33.175077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> we can see our classes names based on the creators name ","metadata":{}},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:33.177941Z","iopub.execute_input":"2022-06-24T02:26:33.178368Z","iopub.status.idle":"2022-06-24T02:26:33.655262Z","shell.execute_reply.started":"2022-06-24T02:26:33.178329Z","shell.execute_reply":"2022-06-24T02:26:33.653993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading valedation dataset ","metadata":{}},{"cell_type":"code","source":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  '/kaggle/working/top5creators_images/val',\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\nval_ds","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:33.657576Z","iopub.execute_input":"2022-06-24T02:26:33.658254Z","iopub.status.idle":"2022-06-24T02:26:33.795448Z","shell.execute_reply.started":"2022-06-24T02:26:33.658216Z","shell.execute_reply":"2022-06-24T02:26:33.794407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading test dataset","metadata":{}},{"cell_type":"code","source":"test_ds = tf.keras.utils.image_dataset_from_directory(\n  '/kaggle/working/top5creators_images/test',\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)\n\ntest_ds","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:33.797073Z","iopub.execute_input":"2022-06-24T02:26:33.797852Z","iopub.status.idle":"2022-06-24T02:26:33.919475Z","shell.execute_reply.started":"2022-06-24T02:26:33.797805Z","shell.execute_reply":"2022-06-24T02:26:33.918457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## display some examples of train images\n#### there is a red message appear when we run the following code\n#### but it is not a error or warning message ,\n#### i think it is just an ordinary message form tensorflow","metadata":{}},{"cell_type":"code","source":"tf.__version__\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:33.920764Z","iopub.execute_input":"2022-06-24T02:26:33.921533Z","iopub.status.idle":"2022-06-24T02:26:33.928918Z","shell.execute_reply.started":"2022-06-24T02:26:33.921492Z","shell.execute_reply":"2022-06-24T02:26:33.92779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### i think the clean up message is showen as there is a new version from tensorflow is \n#### more more updated from the current version of tensorflow on kaggle kernel ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:26:33.930388Z","iopub.execute_input":"2022-06-24T02:26:33.931664Z","iopub.status.idle":"2022-06-24T02:27:06.8076Z","shell.execute_reply.started":"2022-06-24T02:26:33.931572Z","shell.execute_reply":"2022-06-24T02:27:06.806105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## display some test images","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in test_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:27:06.808768Z","iopub.execute_input":"2022-06-24T02:27:06.809155Z","iopub.status.idle":"2022-06-24T02:27:08.780847Z","shell.execute_reply.started":"2022-06-24T02:27:06.809119Z","shell.execute_reply":"2022-06-24T02:27:08.779878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## display val images ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in val_ds.take(1):\n    print(type(images))\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:27:08.782431Z","iopub.execute_input":"2022-06-24T02:27:08.783705Z","iopub.status.idle":"2022-06-24T02:27:15.584331Z","shell.execute_reply.started":"2022-06-24T02:27:08.783648Z","shell.execute_reply":"2022-06-24T02:27:15.58042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image_batch, labels_batch in train_ds:\n    print(image_batch.shape)\n    print(labels_batch.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:27:15.585936Z","iopub.execute_input":"2022-06-24T02:27:15.58658Z","iopub.status.idle":"2022-06-24T02:27:47.301533Z","shell.execute_reply.started":"2022-06-24T02:27:15.586535Z","shell.execute_reply":"2022-06-24T02:27:47.300181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Standardize the data","metadata":{}},{"cell_type":"markdown","source":"> The RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general you should seek to make your input values small.\n\n> Here, you will standardize values to be in the [0, 1] range by using tf.keras.layers.Rescaling:","metadata":{}},{"cell_type":"code","source":"normalization_layer = tf.keras.layers.Rescaling(1./255)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:27:47.303568Z","iopub.execute_input":"2022-06-24T02:27:47.304058Z","iopub.status.idle":"2022-06-24T02:27:47.328821Z","shell.execute_reply.started":"2022-06-24T02:27:47.304011Z","shell.execute_reply":"2022-06-24T02:27:47.327737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configure the dataset for performance ","metadata":{}},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:27:47.330501Z","iopub.execute_input":"2022-06-24T02:27:47.332436Z","iopub.status.idle":"2022-06-24T02:27:47.344047Z","shell.execute_reply.started":"2022-06-24T02:27:47.332383Z","shell.execute_reply":"2022-06-24T02:27:47.342639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create the model","metadata":{}},{"cell_type":"code","source":"# import dependecieces to build our model \nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:27:47.34621Z","iopub.execute_input":"2022-06-24T02:27:47.347024Z","iopub.status.idle":"2022-06-24T02:27:47.353898Z","shell.execute_reply.started":"2022-06-24T02:27:47.346969Z","shell.execute_reply":"2022-06-24T02:27:47.352522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = len(class_names)\n\nmodel = Sequential([\n    layers.Rescaling(1./255, input_shape = (img_height, img_width, 3)),\n    layers.Conv2D(16, 3, padding = 'same', activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding = 'same' , activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(128, activation = 'relu'),\n    layers.Dense(num_classes)\n    \n])","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:27:47.356049Z","iopub.execute_input":"2022-06-24T02:27:47.357001Z","iopub.status.idle":"2022-06-24T02:27:47.45652Z","shell.execute_reply.started":"2022-06-24T02:27:47.356945Z","shell.execute_reply":"2022-06-24T02:27:47.455412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compile The Model ","metadata":{}},{"cell_type":"markdown","source":"> I used Adam optimizer \n\n> Sparse Categorical Cross Entropy as loss function \n\n> ","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer = 'adam',\n             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n             metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:27:47.459048Z","iopub.execute_input":"2022-06-24T02:27:47.459366Z","iopub.status.idle":"2022-06-24T02:27:47.479783Z","shell.execute_reply.started":"2022-06-24T02:27:47.459336Z","shell.execute_reply":"2022-06-24T02:27:47.478542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Summary","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:27:47.481462Z","iopub.execute_input":"2022-06-24T02:27:47.482214Z","iopub.status.idle":"2022-06-24T02:27:47.491788Z","shell.execute_reply.started":"2022-06-24T02:27:47.482158Z","shell.execute_reply":"2022-06-24T02:27:47.490431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the model","metadata":{}},{"cell_type":"code","source":"epochs = 10 \nhistory = model.fit(train_ds,\n                   validation_data = val_ds,\n                   epochs = epochs)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:27:47.493887Z","iopub.execute_input":"2022-06-24T02:27:47.494822Z","iopub.status.idle":"2022-06-24T02:29:11.98759Z","shell.execute_reply.started":"2022-06-24T02:27:47.494767Z","shell.execute_reply":"2022-06-24T02:29:11.986461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Trianing Results ","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize = (8,8))\nplt.subplot(1,2,1)\nplt.plot(epochs_range, acc, label = 'Training Accuracy')\nplt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\nplt.legend(loc = 'lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, loss, label = 'Training Loss')\nplt.plot(epochs_range, val_loss, label = 'Validation Loss')\nplt.legend(loc = 'upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:29:11.988994Z","iopub.execute_input":"2022-06-24T02:29:11.989398Z","iopub.status.idle":"2022-06-24T02:29:12.474984Z","shell.execute_reply.started":"2022-06-24T02:29:11.989348Z","shell.execute_reply":"2022-06-24T02:29:12.473846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"We can see in the above plots taht training accuracy is increasing like linearly over time,\n\nbut validation accuracy stalls around 65% (note : it varies from time to time when i restart the seesion on kaggle )in the training process , \n\nalso the difference in accuracy between training and validation accuracy is noticable \n\nso this is a sign of overfitting \n\nand When there are a small number of training examples ,\n\nthe model sometimes learns from noises or unwanted details from trining examples ,\n\nto extent that it negatively impacts the perfoemance of the model on new expamples .\n\nTo prevent overvitting I will use Dropout and data augmentation \n\n","metadata":{}},{"cell_type":"markdown","source":"# Testing on This Model and Prediction","metadata":{}},{"cell_type":"markdown","source":"## We will take a test image and try to predict it","metadata":{}},{"cell_type":"markdown","source":"## for example we will take an iamge from elenasteem creator and see if the model can predict this creator or not ! :)","metadata":{}},{"cell_type":"code","source":"%ls top5creators_images/test/elenasteem ","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:29:12.47632Z","iopub.execute_input":"2022-06-24T02:29:12.476938Z","iopub.status.idle":"2022-06-24T02:29:13.273156Z","shell.execute_reply.started":"2022-06-24T02:29:12.4769Z","shell.execute_reply":"2022-06-24T02:29:13.271907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if an error appear, just copy image any path from the above the above paths \n# of creator elenasteem and put it in the img_path after /test/elenasteem\nimg_path = 'top5creators_images/test/elenasteem/QmYTk1WCxmidA38RRSEBuRPCxtib6prYD8xBT7GaChhHha.jpg'","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:30:59.796064Z","iopub.execute_input":"2022-06-24T02:30:59.796509Z","iopub.status.idle":"2022-06-24T02:30:59.802816Z","shell.execute_reply.started":"2022-06-24T02:30:59.796475Z","shell.execute_reply":"2022-06-24T02:30:59.801313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the image\nimport matplotlib.image as mpimg\n\ntest_img = mpimg.imread(img_path)\nplt.imshow(test_img)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:01.500944Z","iopub.execute_input":"2022-06-24T02:31:01.501377Z","iopub.status.idle":"2022-06-24T02:31:02.644799Z","shell.execute_reply.started":"2022-06-24T02:31:01.501341Z","shell.execute_reply":"2022-06-24T02:31:02.643593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img = tf.keras.utils.load_img(img_path, target_size = (img_height, img_width))\n\nimg_array = tf.keras.utils.img_to_array(test_img)\nimg_array = tf.expand_dims(img_array, 0) # create the batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\n\nprint(\n\"This image most likely belongs to {} with a {:.2f} percent confidence .\".format(class_names[np.argmax(score)], 100 * np.max(score)))","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:03.549644Z","iopub.execute_input":"2022-06-24T02:31:03.550806Z","iopub.status.idle":"2022-06-24T02:31:04.081915Z","shell.execute_reply.started":"2022-06-24T02:31:03.550762Z","shell.execute_reply":"2022-06-24T02:31:04.08059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## testing all images in elenasteem creator directory","metadata":{}},{"cell_type":"code","source":"%ls top5creators_images/test/elenasteem","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:06.972657Z","iopub.execute_input":"2022-06-24T02:31:06.973448Z","iopub.status.idle":"2022-06-24T02:31:07.766225Z","shell.execute_reply.started":"2022-06-24T02:31:06.973391Z","shell.execute_reply":"2022-06-24T02:31:07.764932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs = tf.keras.utils.image_dataset_from_directory(\n  'top5creators_images/test',\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:08.11313Z","iopub.execute_input":"2022-06-24T02:31:08.113629Z","iopub.status.idle":"2022-06-24T02:31:08.238486Z","shell.execute_reply.started":"2022-06-24T02:31:08.113587Z","shell.execute_reply":"2022-06-24T02:31:08.237116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of images in test folder \ni = 1\n\nfor images, labels in test_imgs.take(1):\n    \n    if i <21:\n        print(\"labels = \", labels)\n        #plt.imshow(mpimg.imread(images[i]))\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        img_array = tf.keras.utils.img_to_array(images[i])\n        img_array = tf.expand_dims(img_array, 0) # create the batch\n\n        predictions = model.predict(img_array)\n        score = tf.nn.softmax(predictions[0])\n\n\n        print(\n        \"This image most likely belongs to {} with a {:.2f} percent confidence .\".format(class_names[np.argmax(score)], 100 * np.max(score)))\n    i+=1","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:13.017812Z","iopub.execute_input":"2022-06-24T02:31:13.018629Z","iopub.status.idle":"2022-06-24T02:31:14.70883Z","shell.execute_reply.started":"2022-06-24T02:31:13.01858Z","shell.execute_reply":"2022-06-24T02:31:14.707839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## to make sure that this images is belongs to the same creator in the prediction \n## i will print all images in test directory and thier labels","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, labels in test_imgs.take(1):\n    print(type(images))\n    \n    # we specify 21 according to number of images in the test directory to show all images \n    # and compare them with the predicted image\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:24.764833Z","iopub.execute_input":"2022-06-24T02:31:24.765495Z","iopub.status.idle":"2022-06-24T02:31:26.756936Z","shell.execute_reply.started":"2022-06-24T02:31:24.765451Z","shell.execute_reply":"2022-06-24T02:31:26.755918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Overfitting ","metadata":{}},{"cell_type":"markdown","source":"#### We can see the availabel images in test directory it's varies every time we run this notebook\n\n#### as the distribution of images in every time is randomlly dirstibuted from top5creators directory\n\n#### to top5creators_images directory but we can make sure that this image belongs to the creator \n\n#### by exploring out csv file and select it's cid \n\n#### and we can copy the cid from test directory after we make usre that is belongs to\n\n#### the same creator , and then assign this path to the following varibale img_path","metadata":{}},{"cell_type":"markdown","source":"# Data Augmentaion","metadata":{}},{"cell_type":"code","source":"data_augmentation = keras.Sequential([\n    layers.RandomFlip(\"horizontal\",\n                     input_shape=(img_height,img_width,3)),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1)\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:31.319289Z","iopub.execute_input":"2022-06-24T02:31:31.319732Z","iopub.status.idle":"2022-06-24T02:31:31.463795Z","shell.execute_reply.started":"2022-06-24T02:31:31.319692Z","shell.execute_reply":"2022-06-24T02:31:31.462629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize some random images after augmentated them","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\n\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:32.585036Z","iopub.execute_input":"2022-06-24T02:31:32.585441Z","iopub.status.idle":"2022-06-24T02:31:33.377026Z","shell.execute_reply.started":"2022-06-24T02:31:32.585407Z","shell.execute_reply":"2022-06-24T02:31:33.375611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dropout","metadata":{}},{"cell_type":"markdown","source":"> When Using dropout to a lyer , it randomly dropouts a number of output units from the layer during the training process \n\n> Dropout takes a fractional number as it's input value , in the form such as 0.2 , 0.4 , and so on \n\n> this means dropping out by 20% or 40% of the output unit randomly from the applied layer","metadata":{}},{"cell_type":"code","source":"model = Sequential([\n    data_augmentation,\n    layers.Rescaling(1./255),\n    layers.Conv2D(16, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding='same', activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.2),\n    layers.Flatten(),\n    layers.Dense(128, activation = 'relu'),\n    layers.Dense(num_classes)\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:36.849852Z","iopub.execute_input":"2022-06-24T02:31:36.850289Z","iopub.status.idle":"2022-06-24T02:31:37.043433Z","shell.execute_reply.started":"2022-06-24T02:31:36.850254Z","shell.execute_reply":"2022-06-24T02:31:37.042065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Compile and train the model","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer = 'adam',\n             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n             metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:39.904467Z","iopub.execute_input":"2022-06-24T02:31:39.905265Z","iopub.status.idle":"2022-06-24T02:31:39.920405Z","shell.execute_reply.started":"2022-06-24T02:31:39.905215Z","shell.execute_reply":"2022-06-24T02:31:39.918731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:40.615791Z","iopub.execute_input":"2022-06-24T02:31:40.616255Z","iopub.status.idle":"2022-06-24T02:31:40.625038Z","shell.execute_reply.started":"2022-06-24T02:31:40.616221Z","shell.execute_reply":"2022-06-24T02:31:40.623279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\n\nhistory = model.fit(\ntrain_ds,\nvalidation_data = val_ds,\nepochs = epochs)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:31:42.251844Z","iopub.execute_input":"2022-06-24T02:31:42.252299Z","iopub.status.idle":"2022-06-24T02:32:08.909543Z","shell.execute_reply.started":"2022-06-24T02:31:42.252262Z","shell.execute_reply":"2022-06-24T02:32:08.908366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize training results ","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize =  (8,8))\nplt.subplot(1,2,1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc = 'lower right')\nplt.title('Training and Validation Acuuracy')\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc = 'upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:32:11.635913Z","iopub.execute_input":"2022-06-24T02:32:11.637146Z","iopub.status.idle":"2022-06-24T02:32:12.00601Z","shell.execute_reply.started":"2022-06-24T02:32:11.637091Z","shell.execute_reply":"2022-06-24T02:32:12.004891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing The Model and Prediction","metadata":{}},{"cell_type":"markdown","source":"### We will take a test image and try to predict it","metadata":{}},{"cell_type":"markdown","source":"## for example we will take an iamge from artxmike creator and see if the model can predict this creator or not ! :)","metadata":{}},{"cell_type":"code","source":"%ls top5creators_images/test/artxmike ","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:34:39.202038Z","iopub.execute_input":"2022-06-24T02:34:39.202762Z","iopub.status.idle":"2022-06-24T02:34:40.021356Z","shell.execute_reply.started":"2022-06-24T02:34:39.202713Z","shell.execute_reply":"2022-06-24T02:34:40.019972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PHOTO_DATA[PHOTO_DATA['creator'] == 'artxmike']['cid']","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:34:58.827676Z","iopub.execute_input":"2022-06-24T02:34:58.82828Z","iopub.status.idle":"2022-06-24T02:34:58.85272Z","shell.execute_reply.started":"2022-06-24T02:34:58.828227Z","shell.execute_reply":"2022-06-24T02:34:58.851526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = 'top5creators_images/test/artxmike/QmUPkctx6YzMHGcZtD6Eb5hoi6qNgmfTCBjViVH6nFKFG8.jpeg'","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:25.537955Z","iopub.execute_input":"2022-06-24T02:35:25.538613Z","iopub.status.idle":"2022-06-24T02:35:25.544212Z","shell.execute_reply.started":"2022-06-24T02:35:25.538571Z","shell.execute_reply":"2022-06-24T02:35:25.5429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the image\nimport matplotlib.image as mpimg\n\ntest_img = mpimg.imread(img_path)\nplt.imshow(test_img)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:25.73214Z","iopub.execute_input":"2022-06-24T02:35:25.732561Z","iopub.status.idle":"2022-06-24T02:35:27.368625Z","shell.execute_reply.started":"2022-06-24T02:35:25.732526Z","shell.execute_reply":"2022-06-24T02:35:27.367383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img = tf.keras.utils.load_img(img_path, target_size = (img_height, img_width))\nimg_array = tf.keras.utils.img_to_array(test_img)\nimg_array = tf.expand_dims(img_array, 0) # create the batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\n\nprint(\n\"This image most likely belongs to {} with a {:.2f} percent confidence .\"\n.format(class_names[np.argmax(score)], 100 * np.max(score)))","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:28.716834Z","iopub.execute_input":"2022-06-24T02:35:28.717939Z","iopub.status.idle":"2022-06-24T02:35:28.972701Z","shell.execute_reply.started":"2022-06-24T02:35:28.71788Z","shell.execute_reply":"2022-06-24T02:35:28.971596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## I will use another approach based on files locations \n## so i will use only the top5creators directory to load images \n## and split them to train and val sets","metadata":{}},{"cell_type":"markdown","source":"### loading data","metadata":{}},{"cell_type":"code","source":"import pathlib\ndata_dir = pathlib.Path(\"top5creators\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:39.009564Z","iopub.execute_input":"2022-06-24T02:35:39.009959Z","iopub.status.idle":"2022-06-24T02:35:39.015555Z","shell.execute_reply.started":"2022-06-24T02:35:39.009924Z","shell.execute_reply":"2022-06-24T02:35:39.014364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### loading train, val and test datasets","metadata":{}},{"cell_type":"code","source":"image_count = len(list(data_dir.glob('*/*.*')))\n\nlist_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\nlist_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n\n\nval_size = int(image_count * 0.2)\ntest_size = int(image_count * 0.1)\n\ntrain_ds = list_ds.skip(val_size)\ntest_ds = list_ds.take(test_size)\nval_ds = list_ds.take(val_size)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:40.570541Z","iopub.execute_input":"2022-06-24T02:35:40.570979Z","iopub.status.idle":"2022-06-24T02:35:40.601008Z","shell.execute_reply.started":"2022-06-24T02:35:40.570942Z","shell.execute_reply":"2022-06-24T02:35:40.599829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_count","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:42.330959Z","iopub.execute_input":"2022-06-24T02:35:42.331598Z","iopub.status.idle":"2022-06-24T02:35:42.339112Z","shell.execute_reply.started":"2022-06-24T02:35:42.331562Z","shell.execute_reply":"2022-06-24T02:35:42.337772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.data.experimental.cardinality(train_ds).numpy())\nprint(tf.data.experimental.cardinality(val_ds).numpy())\nprint(tf.data.experimental.cardinality(test_ds).numpy())\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:42.62469Z","iopub.execute_input":"2022-06-24T02:35:42.625392Z","iopub.status.idle":"2022-06-24T02:35:42.634848Z","shell.execute_reply.started":"2022-06-24T02:35:42.62535Z","shell.execute_reply":"2022-06-24T02:35:42.63318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(list(range(10,20)))","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:43.161284Z","iopub.execute_input":"2022-06-24T02:35:43.162505Z","iopub.status.idle":"2022-06-24T02:35:43.169108Z","shell.execute_reply.started":"2022-06-24T02:35:43.162446Z","shell.execute_reply":"2022-06-24T02:35:43.167817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for f in train_ds.take(15):\n    print(f.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:44.095371Z","iopub.execute_input":"2022-06-24T02:35:44.096278Z","iopub.status.idle":"2022-06-24T02:35:44.116956Z","shell.execute_reply.started":"2022-06-24T02:35:44.096215Z","shell.execute_reply":"2022-06-24T02:35:44.1156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_label(file_path):\n  # Convert the path to a list of path components\n    parts = tf.strings.split(file_path, os.path.sep)\n    print(\"parts = \", parts)\n  # The second to last is the class-directory\n    one_hot = parts[-2] == class_names\n    print(\"parts[-2] = \", parts[-2])\n    print(\"file_path = \", file_path)\n    print(\"one hot = \",one_hot)\n    print(\"class names = \", class_names)\n    \n  # Integer encode the label\n    return tf.argmax(one_hot)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:45.224603Z","iopub.execute_input":"2022-06-24T02:35:45.225374Z","iopub.status.idle":"2022-06-24T02:35:45.234207Z","shell.execute_reply.started":"2022-06-24T02:35:45.225324Z","shell.execute_reply":"2022-06-24T02:35:45.232694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_img(img):\n  # Convert the compressed string to a 3D uint8 tensor\n  img = tf.io.decode_image(img, channels=3,expand_animations = False )\n  # Resize the image to the desired size\n  return tf.image.resize(img, [img_height, img_width])","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:46.032109Z","iopub.execute_input":"2022-06-24T02:35:46.034192Z","iopub.status.idle":"2022-06-24T02:35:46.041501Z","shell.execute_reply.started":"2022-06-24T02:35:46.034133Z","shell.execute_reply":"2022-06-24T02:35:46.040147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_path(file_path):\n    label = get_label(file_path)\n    # Load the raw data from the file as a string\n    img = tf.io.read_file(file_path)\n    img = decode_img(img)\n    return img, label","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:46.584315Z","iopub.execute_input":"2022-06-24T02:35:46.585209Z","iopub.status.idle":"2022-06-24T02:35:46.591918Z","shell.execute_reply.started":"2022-06-24T02:35:46.585142Z","shell.execute_reply":"2022-06-24T02:35:46.590334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\ntrain_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.map(process_path, num_parallel_calls = AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:47.432313Z","iopub.execute_input":"2022-06-24T02:35:47.432719Z","iopub.status.idle":"2022-06-24T02:35:47.742074Z","shell.execute_reply.started":"2022-06-24T02:35:47.432685Z","shell.execute_reply":"2022-06-24T02:35:47.740718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.data.experimental.cardinality(train_ds).numpy())\nprint(tf.data.experimental.cardinality(val_ds).numpy())\nprint(tf.data.experimental.cardinality(test_ds).numpy())\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:48.409714Z","iopub.execute_input":"2022-06-24T02:35:48.410605Z","iopub.status.idle":"2022-06-24T02:35:48.419201Z","shell.execute_reply.started":"2022-06-24T02:35:48.410559Z","shell.execute_reply":"2022-06-24T02:35:48.417542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, label in train_ds.take(1):\n      print(\"Image shape: \", image.numpy().shape)\n      print(\"Label: \", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:49.484601Z","iopub.execute_input":"2022-06-24T02:35:49.485616Z","iopub.status.idle":"2022-06-24T02:35:49.727246Z","shell.execute_reply.started":"2022-06-24T02:35:49.485566Z","shell.execute_reply":"2022-06-24T02:35:49.726102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, label in val_ds.take(1):\n      print(\"Image shape: \", image.numpy().shape)\n      print(\"Label: \", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:50.360163Z","iopub.execute_input":"2022-06-24T02:35:50.36058Z","iopub.status.idle":"2022-06-24T02:35:50.510941Z","shell.execute_reply.started":"2022-06-24T02:35:50.360545Z","shell.execute_reply":"2022-06-24T02:35:50.509786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, label in test_ds.take(3):\n    print(\"Image shape: \", image.numpy().shape)\n    print(\"Label: \", label.numpy())\n    #plt.imshow(image[0].numpy().astype(\"uint8\"))  ","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:52.254243Z","iopub.execute_input":"2022-06-24T02:35:52.256253Z","iopub.status.idle":"2022-06-24T02:35:52.431808Z","shell.execute_reply.started":"2022-06-24T02:35:52.256195Z","shell.execute_reply":"2022-06-24T02:35:52.428918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def configure_for_performance(ds):\n    ds = ds.cache()\n    ds = ds.shuffle(buffer_size=1000)\n    #ds = ds.batch(batch_size)\n    ds = ds.batch(5)\n    ds = ds.prefetch(buffer_size=AUTOTUNE)\n    return ds\n\ntrain_ds = configure_for_performance(train_ds)\nval_ds = configure_for_performance(val_ds)\ntest_ds = configure_for_performance(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:35:53.701626Z","iopub.execute_input":"2022-06-24T02:35:53.702388Z","iopub.status.idle":"2022-06-24T02:35:53.716804Z","shell.execute_reply.started":"2022-06-24T02:35:53.702342Z","shell.execute_reply":"2022-06-24T02:35:53.715516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#image_batch, label_batch = next(iter(test_ds))\n\n\n'''\nplt.figure(figsize=(10, 10))\nfor i in range(tf.data.experimental.cardinality(test_ds).numpy()):\n    image, label in val_ds.take(i)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image[i].numpy().astype(\"uint8\"))\n    label = label[i]\n    plt.title(class_names[label])\n    plt.axis(\"off\")'''","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:29:13.686183Z","iopub.status.idle":"2022-06-24T02:29:13.68688Z","shell.execute_reply.started":"2022-06-24T02:29:13.686612Z","shell.execute_reply":"2022-06-24T02:29:13.686636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### build the model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\n\nnum_classes = len(class_names)\n\n# build the model with Dropout and regulariztion\n\n\n\nmodel = Sequential([\n    data_augmentation,\n    layers.Rescaling(1./255),\n    layers.Conv2D(32, 3, padding='same', activation='relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(180, 3, padding='same', activation = 'relu'),\n    #layers.MaxPooling2D(),\n    #layers.Conv2D(180, 3, padding = 'same', activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.2),\n    layers.Flatten(),\n    layers.Dense(360, activation = 'relu'),\n    #layers.Dense(num_classes)\n    layers.Dense(num_classes,\n                     #kernel_initializer='ones',\n                     kernel_regularizer=regularizers.L1(0.01),\n                     activity_regularizer=regularizers.L2(0.01))\n    \n])\n\n\n'''\nmodel = Sequential([\n    layers.Rescaling(1./255, input_shape = (img_height, img_width, 3)),\n    layers.Conv2D(16, 3, padding = 'same', activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, padding = 'same' , activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, padding = 'same', activation = 'relu'),\n    layers.MaxPooling2D(),\n    layers.Dropout(0.4),\n    layers.Flatten(),\n    layers.Dense(128, activation = 'relu'),\n    #layers.Dense(num_classes)\n    layers.Dense(num_classes,\n                     kernel_initializer='ones',\n                     kernel_regularizer=regularizers.L1(0.01),\n                     activity_regularizer=regularizers.L2(0.01))\n    \n])'''","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:36:02.58808Z","iopub.execute_input":"2022-06-24T02:36:02.588811Z","iopub.status.idle":"2022-06-24T02:36:02.82363Z","shell.execute_reply.started":"2022-06-24T02:36:02.588763Z","shell.execute_reply":"2022-06-24T02:36:02.822387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'adam',\n             loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n             metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:36:04.572508Z","iopub.execute_input":"2022-06-24T02:36:04.572956Z","iopub.status.idle":"2022-06-24T02:36:04.586206Z","shell.execute_reply.started":"2022-06-24T02:36:04.57291Z","shell.execute_reply":"2022-06-24T02:36:04.584809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:36:05.395957Z","iopub.execute_input":"2022-06-24T02:36:05.396689Z","iopub.status.idle":"2022-06-24T02:36:05.406035Z","shell.execute_reply.started":"2022-06-24T02:36:05.396641Z","shell.execute_reply":"2022-06-24T02:36:05.403538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=50\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:36:07.131997Z","iopub.execute_input":"2022-06-24T02:36:07.132377Z","iopub.status.idle":"2022-06-24T02:39:20.02119Z","shell.execute_reply.started":"2022-06-24T02:36:07.132344Z","shell.execute_reply":"2022-06-24T02:39:20.020107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(50)\n\nplt.figure(figsize =  (8,8))\nplt.subplot(1,2,1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc = 'lower right')\nplt.title('Training and Validation Acuuracy')\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc = 'upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:40:44.697564Z","iopub.execute_input":"2022-06-24T02:40:44.698034Z","iopub.status.idle":"2022-06-24T02:40:45.219706Z","shell.execute_reply.started":"2022-06-24T02:40:44.698001Z","shell.execute_reply":"2022-06-24T02:40:45.218532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### thest the following image \n### this image belongs to the creator elgeko ","metadata":{}},{"cell_type":"code","source":"%ls top5creators_images/test/elgeko/","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:40:51.483094Z","iopub.execute_input":"2022-06-24T02:40:51.483741Z","iopub.status.idle":"2022-06-24T02:40:52.261619Z","shell.execute_reply.started":"2022-06-24T02:40:51.483698Z","shell.execute_reply":"2022-06-24T02:40:52.260245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_path = 'top5creators_images/test/elgeko/QmZqYLaEtqeCdAbSjJiMPDGoirxGmb6hEoXxmSWHTApRUC.png'\n\n\n\n# show the image\nimport matplotlib.image as mpimg\n\ntest_img = mpimg.imread(img_path)\nplt.imshow(test_img)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:40:53.850973Z","iopub.execute_input":"2022-06-24T02:40:53.851475Z","iopub.status.idle":"2022-06-24T02:40:54.708073Z","shell.execute_reply.started":"2022-06-24T02:40:53.851419Z","shell.execute_reply":"2022-06-24T02:40:54.706936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntest_img = tf.keras.utils.load_img(img_path, target_size = (img_height, img_width))\nimg_array = tf.keras.utils.img_to_array(test_img)\nimg_array = tf.expand_dims(img_array, 0) # create the batch\n\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\n\n\nprint(\n\"This image most likely belongs to {} with a {:.2f} percent confidence .\"\n.format(class_names[np.argmax(score)], 100 * np.max(score))) ","metadata":{"execution":{"iopub.status.busy":"2022-06-24T02:40:58.10638Z","iopub.execute_input":"2022-06-24T02:40:58.106759Z","iopub.status.idle":"2022-06-24T02:40:58.334899Z","shell.execute_reply.started":"2022-06-24T02:40:58.106728Z","shell.execute_reply":"2022-06-24T02:40:58.333935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### it predict succefully the image","metadata":{}}]}